{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7033fee5-58b1-4976-b62b-b561086cce28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilias/.pyenv/versions/3.8.0/envs/vs/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from scipy.ndimage import binary_fill_holes, binary_dilation, binary_erosion\n",
    "from skimage.measure import label, regionprops\n",
    "from models.combogan_model_pred import ComboGANModel\n",
    "import torch\n",
    "from imantics import Polygons, Mask, BBox\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from openslide import OpenSlide\n",
    "from collections import Counter\n",
    "from openslide import lowlevel\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "import pyvips\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23aff3e2-b6db-4fee-b081-592bade11703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_tiles = [0,1,2,3,4]\n",
    "15 + 60*2/len(path_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ad0017-d0b8-426a-bc53-415172ba60a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilias/.pyenv/versions/3.8.0/envs/vs/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:03<00:00,  1.18s/it]\n",
      "/home/ilias/.pyenv/versions/3.8.0/envs/vs/lib/python3.8/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks initialized -------------\n",
      "ResnetGenEncoder(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): PReLU(num_parameters=1)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): PReLU(num_parameters=1)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): PReLU(num_parameters=1)\n",
      "    (10): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (11): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (12): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (13): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResnetGenDecoder(\n",
      "  (model): Sequential(\n",
      "    (0): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (1): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (2): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (3): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (4): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (5): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (7): PReLU(num_parameters=1)\n",
      "    (8): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (10): PReLU(num_parameters=1)\n",
      "    (11): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (12): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "Created 9 Encoder-Decoder pairs\n",
      "Number of parameters per Encoder: 5099143\n",
      "Number of parameters per Deocder: 6565770\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/21 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 177\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstrerror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m he_slide_path  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHE.ndpi\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 177\u001b[0m \u001b[43mextraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhe_slide_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgpu_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 83\u001b[0m, in \u001b[0;36mextraction\u001b[0;34m(he_slide_path, gpu_ids, real_wsi_id)\u001b[0m\n\u001b[1;32m     80\u001b[0m bundle \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m: torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mexpand_dims(he_img, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDA\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     81\u001b[0m           torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m8\u001b[39m]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m: [path]}\n\u001b[1;32m     82\u001b[0m model\u001b[38;5;241m.\u001b[39mset_input(bundle)\n\u001b[0;32m---> 83\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m visuals \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_current_visuals(testing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     86\u001b[0m short_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(path)\n",
      "File \u001b[0;32m~/Downloads/VS/models/combogan_model_pred.py:86\u001b[0m, in \u001b[0;36mComboGANModel.test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDA:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m fake \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisuals\u001b[38;5;241m.\u001b[39mappend( fake )\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mappend( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfake_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m d )\n",
      "File \u001b[0;32m~/Downloads/VS/models/networks.py:382\u001b[0m, in \u001b[0;36mG_Plexer.decode\u001b[0;34m(self, input, domain)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msharing:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_decoder\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28minput\u001b[39m, domain)\n\u001b[0;32m--> 382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/VS/models/networks.py:203\u001b[0m, in \u001b[0;36mResnetGenDecoder.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_ids \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdata, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mFloatTensor):\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39mdata_parallel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_ids)\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/vs/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/vs/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/vs/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/vs/lib/python3.8/site-packages/torch/nn/modules/conv.py:956\u001b[0m, in \u001b[0;36mConvTranspose2d.forward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    951\u001b[0m num_spatial_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    952\u001b[0m output_padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_padding(\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28minput\u001b[39m, output_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    954\u001b[0m     num_spatial_dims, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m--> 956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_transpose2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_padding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def extraction(he_slide_path,gpu_ids = [0],real_wsi_id = 'destination'):\n",
    "    # Choosing the magnification level\n",
    "    slide_dim_lvl = 5\n",
    "    # Patch size in pixels (x40) \n",
    "    patch_size = 2048\n",
    "    # Slide ID\n",
    "    #real_wsi_id = 'sample_vs'\n",
    "    # Path to save data\n",
    "    path_to_save_patches = os.path.join('sample_staining', 'he_patches', real_wsi_id)\n",
    "    os.makedirs(path_to_save_patches ,exist_ok=True)\n",
    "\n",
    "    # Path to save data\n",
    "    save_WSIs = os.path.join('sample_staining', 'slides', real_wsi_id)\n",
    "    os.makedirs(save_WSIs ,exist_ok=True)\n",
    "\n",
    "    os.makedirs(os.path.join('sample_staining', 'GAN', real_wsi_id) ,exist_ok=True) \n",
    "\n",
    "    # Opening the slides\n",
    "    he_slide  = OpenSlide(he_slide_path)\n",
    "    low_slide = lowlevel.open(he_slide_path)\n",
    "    keys = lowlevel.get_property_names(low_slide)\n",
    "\n",
    "    # Getting slides level dimensions\n",
    "    he_slide_levels = he_slide.level_dimensions\n",
    "\n",
    "\n",
    "    scale_factor = math.ceil(he_slide_levels[0][0]/he_slide_levels[slide_dim_lvl][0])\n",
    "    new_patch_size = math.ceil(patch_size/ scale_factor)\n",
    "\n",
    "    # Getting the thumbnail for the slides\n",
    "    he_thm  = he_slide.read_region((0, 0), slide_dim_lvl, he_slide_levels[slide_dim_lvl])\n",
    "\n",
    "    clean_label_image, polygons = cluster_wsi(he_thm, plot=False)\n",
    "\n",
    "\n",
    "    for poly_id in tqdm(range(len(polygons.points))):\n",
    "        tmp_bn_img = np.zeros(np.shape(clean_label_image))\n",
    "        rr, cc = np.where(clean_label_image==int(len(polygons.points)-poly_id))\n",
    "        tmp_bn_img[rr,cc] = 1\n",
    "\n",
    "        # plt.plot(polygons.points[poly_id][:,0], polygons.points[poly_id][:,1], label='Slide region: '+str(poly_id))\n",
    "        xmin, xmax = np.min(polygons.points[poly_id][:,0]), np.max(polygons.points[poly_id][:,0])\n",
    "        ymin, ymax = np.min(polygons.points[poly_id][:,1]), np.max(polygons.points[poly_id][:,1])\n",
    "        # plt.gca().add_patch(Rectangle((xmin, ymin), xmax-xmin, ymax-ymin,edgecolor='gray', facecolor='none', lw=1, ls=\"--\"))\n",
    "\n",
    "        x_patches = math.ceil((xmax - xmin)/ new_patch_size)\n",
    "        y_patches = math.ceil((ymax - ymin)/ new_patch_size)\n",
    "\n",
    "        for y_id in range(1, math.ceil(y_patches)+1):\n",
    "            for x_id in range(1, math.ceil(x_patches)+1):\n",
    "                tmp_x_corr, tmp_y_corr = xmin+((x_id-1)*new_patch_size), ymin+((y_id-1)*new_patch_size)\n",
    "                if (tmp_bn_img[tmp_y_corr:tmp_y_corr+new_patch_size, tmp_x_corr:tmp_x_corr+new_patch_size].sum()/ new_patch_size**2) >0.05:\n",
    "\n",
    "                    path_he_thm  = he_slide.read_region((int(tmp_x_corr*scale_factor), int(tmp_y_corr*scale_factor)), 0, (patch_size, patch_size))\n",
    "\n",
    "                    path_he_thm.save(os.path.join(path_to_save_patches, f'tile_{patch_size}_{int(tmp_x_corr*scale_factor)}_{int(tmp_y_corr*scale_factor)}.tif'))\n",
    "                    # print(x_id-1,y_id-1)\n",
    "\n",
    "\n",
    "    model = ComboGANModel(which_epoch=885, save_dir=os.path.join('./checkpoints', 'stain_aligned_comGan-512'),gpu_ids = gpu_ids)\n",
    "\n",
    "    def get_transform():\n",
    "        transform_list = []\n",
    "        transform_list.append(transforms.Resize(512, Image.BICUBIC))\n",
    "        transform_list += [transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                (0.5, 0.5, 0.5))]\n",
    "        return transforms.Compose(transform_list)\n",
    "\n",
    "\n",
    "    # Get tiles paths\n",
    "    path_tiles = natsorted(glob(os.path.join(path_to_save_patches, '*.tif')))\n",
    "\n",
    "    transform = get_transform()\n",
    "    for path in tqdm(path_tiles):\n",
    "        he_img = Image.open(path).convert('RGB')\n",
    "\n",
    "        he_img = transform(he_img)\n",
    "\n",
    "        bundle = {'A': torch.tensor(np.expand_dims(he_img, axis=0)), 'DA':\n",
    "                  torch.tensor([8]), 'path': [path]}\n",
    "        model.set_input(bundle)\n",
    "        model.test()\n",
    "        visuals = model.get_current_visuals(testing=True)\n",
    "\n",
    "        short_path = os.path.basename(path)\n",
    "        name = os.path.splitext(short_path)[0]\n",
    "\n",
    "        for label, image_numpy in visuals.items():\n",
    "            image_name = '%s_%s.tif' % (name, label)\n",
    "            save_path = os.path.join('sample_staining', 'GAN', real_wsi_id,image_name)\n",
    "            Image.fromarray(image_numpy).save(save_path)\n",
    "\n",
    "\n",
    "\n",
    "    for stain_id_fake in trange(0, 9):\n",
    "\n",
    "\n",
    "        # Get tiles paths\n",
    "        path_tiles = natsorted(glob(os.path.join('sample_staining', 'GAN', real_wsi_id, '*'+str(stain_id_fake)+'.tif')))\n",
    "\n",
    "        # Getting the x rows and y columns\n",
    "        _, patch_size, x_rows, y_colms, stain, modality =os.path.splitext(os.path.basename(path_tiles[len(path_tiles)-1]))[0].split('_')\n",
    "\n",
    "        x_mins, y_mins = [], []\n",
    "        for path in path_tiles:\n",
    "            # Getting the x rows and y columns\n",
    "            _, patch_size, x_min, y_min, stain, modality =os.path.splitext(os.path.basename(path))[0].split('_')\n",
    "\n",
    "            x_mins.append(int(x_min))\n",
    "            y_mins.append(int(y_min))\n",
    "\n",
    "\n",
    "        all_slide = np.ones((np.max(y_mins)-np.min(y_mins)+int(patch_size), np.max(x_mins)-np.min(x_mins)+int(patch_size), 3))*255\n",
    "\n",
    "        for path in path_tiles:\n",
    "            # Getting the x rows and y columns\n",
    "            _, patch_size, x_min, y_min, stain, modality =os.path.splitext(os.path.basename(path))[0].split('_')\n",
    "\n",
    "            x_min      = int(x_min) - np.min(x_mins)\n",
    "            y_min      = int(y_min) - np.min(y_mins)\n",
    "            patch_size = int(patch_size)\n",
    "\n",
    "            tmp_array = np.array(Image.open(path).resize((2048, 2048)))[:,:,0:3]\n",
    "\n",
    "\n",
    "            all_slide[y_min:y_min+patch_size, x_min:x_min+patch_size, :] = tmp_array\n",
    "\n",
    "        pyramid = pyvips.Image.new_from_array(all_slide)\n",
    "\n",
    "        del all_slide\n",
    "        # Add metadata\n",
    "        # metadata = {'ResolutionUnit': 'micrometers',\n",
    "        #             'openslide.mpp-x': float(lowlevel.get_property_value(low_slide,keys[108])),\n",
    "        #             'openslide.mpp-y': float(lowlevel.get_property_value(low_slide,keys[109])),\n",
    "        #             'openslide.objective-power': float(lowlevel.get_property_value(low_slide,keys[110])),\n",
    "        #             }shutil\n",
    "        # tiff.Model: C13210\n",
    "        # tiff.ResolutionUnit: centimeter\n",
    "        # tiff.Software: NDP.scan 3.2.15\n",
    "        # tiff.XResolution: 45344\n",
    "        # tiff.YResolution: 45344\n",
    "        # slide-associated-images: macro\n",
    "\n",
    "        # pyramid.set_type(pyvips.GValue.gint_type, \"openslide.objective-power\", metadata['openslide.objective-power'])\n",
    "        # pyramid.set_type(pyvips.GValue.gdouble_type,    \"openslide.mpp-x\", metadata['openslide.mpp-x'])\n",
    "        # pyramid.set_type(pyvips.GValue.gdouble_type,    \"openslide.mpp-y\", metadata['openslide.mpp-y'])\n",
    "        # pyramid.set_type(pyvips.GValue.gint_type,    \"tiff.XResolution\", 45344)\n",
    "        # pyramid.set_type(pyvips.GValue.gint_type,    \"tiff.YResolution\", 45344)\n",
    "        # pyramid.set_type(pyvips.GValue.gstr_type,    \"tiff.ResolutionUnit\", \"centimeter\")\n",
    "        # pyramid.set_type(pyvips.GValue.gstr_type,    \"tiff.Model\", \"C13210\")\n",
    "        # pyramid.set_type(pyvips.GValue.gstr_type,    \"tiff.Make\", \"Hamamatsu\")\n",
    "        # pyramid.set_type(pyvips.GValue.gint_type, \"hamamatsu.SourceLens\",40)\n",
    "\n",
    "        pyramid.tiffsave(os.path.join(save_WSIs, 'WSI_'+stain+'_'+modality+'.tif'), \n",
    "                    compression=\"jpeg\", \n",
    "                    Q=100, \n",
    "                    tile=True, \n",
    "                    tile_width=512, \n",
    "                    tile_height=512, \n",
    "                    pyramid=True)\n",
    "\n",
    "\n",
    "        del pyramid\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(path_to_save_patches)\n",
    "        shutil.rmtree(os.path.join('sample_staining', 'GAN', real_wsi_id))\n",
    "        print(\"Temp folders has been deleted.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: {e.strerror}\")\n",
    "\n",
    "        \n",
    "he_slide_path  = 'HE.ndpi'\n",
    "extraction(he_slide_path,gpu_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2c04279-c2bc-4312-9bdb-686f541bfc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cytomine import CytomineJob\n",
    "from cytomine.models import ImageInstance\n",
    "from extraction_utils import extraction\n",
    "from cytomine import Cytomine\n",
    "from cytomine.models import StorageCollection, Project, UploadedFile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7067f69-a8e0-4036-8006-86967450b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee2981e9-4106-439e-aeb2-4489cd0d1dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilias/.pyenv/versions/3.8.0/envs/vs/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:04<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks initialized -------------\n",
      "ResnetGenEncoder(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): PReLU(num_parameters=1)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): PReLU(num_parameters=1)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): PReLU(num_parameters=1)\n",
      "    (10): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (11): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (12): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (13): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResnetGenDecoder(\n",
      "  (model): Sequential(\n",
      "    (0): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (1): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (2): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (3): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (4): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (5): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (7): PReLU(num_parameters=1)\n",
      "    (8): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (10): PReLU(num_parameters=1)\n",
      "    (11): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (12): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "Created 9 Encoder-Decoder pairs\n",
      "Number of parameters per Encoder: 5099143\n",
      "Number of parameters per Deocder: 6565770\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "he_slide_path  = 'HE.ndpi'\n",
    "gpu_ids=[]\n",
    "real_wsi_id = 'destination'\n",
    "\n",
    "# Choosing the magnification level\n",
    "slide_dim_lvl = 5\n",
    "# Patch size in pixels (x40) \n",
    "patch_size = 2048\n",
    "# Slide ID\n",
    "#real_wsi_id = 'sample_vs'\n",
    "# Path to save data\n",
    "path_to_save_patches = os.path.join('sample_staining', 'he_patches', real_wsi_id)\n",
    "os.makedirs(path_to_save_patches ,exist_ok=True)\n",
    "\n",
    "# Path to save data\n",
    "save_WSIs = os.path.join('sample_staining', 'slides', real_wsi_id)\n",
    "os.makedirs(save_WSIs ,exist_ok=True)\n",
    "\n",
    "os.makedirs(os.path.join('sample_staining', 'GAN', real_wsi_id) ,exist_ok=True) \n",
    "\n",
    "# Opening the slides\n",
    "he_slide  = OpenSlide(he_slide_path)\n",
    "low_slide = lowlevel.open(he_slide_path)\n",
    "keys = lowlevel.get_property_names(low_slide)\n",
    "\n",
    "# Getting slides level dimensions\n",
    "he_slide_levels = he_slide.level_dimensions\n",
    "\n",
    "\n",
    "scale_factor = math.ceil(he_slide_levels[0][0]/he_slide_levels[slide_dim_lvl][0])\n",
    "new_patch_size = math.ceil(patch_size/ scale_factor)\n",
    "\n",
    "# Getting the thumbnail for the slides\n",
    "he_thm  = he_slide.read_region((0, 0), slide_dim_lvl, he_slide_levels[slide_dim_lvl])\n",
    "\n",
    "clean_label_image, polygons = cluster_wsi(he_thm, plot=False)\n",
    "\n",
    "\n",
    "for poly_id in tqdm(range(len(polygons.points))):\n",
    "    tmp_bn_img = np.zeros(np.shape(clean_label_image))\n",
    "    rr, cc = np.where(clean_label_image==int(len(polygons.points)-poly_id))\n",
    "    tmp_bn_img[rr,cc] = 1\n",
    "\n",
    "    # plt.plot(polygons.points[poly_id][:,0], polygons.points[poly_id][:,1], label='Slide region: '+str(poly_id))\n",
    "    xmin, xmax = np.min(polygons.points[poly_id][:,0]), np.max(polygons.points[poly_id][:,0])\n",
    "    ymin, ymax = np.min(polygons.points[poly_id][:,1]), np.max(polygons.points[poly_id][:,1])\n",
    "    # plt.gca().add_patch(Rectangle((xmin, ymin), xmax-xmin, ymax-ymin,edgecolor='gray', facecolor='none', lw=1, ls=\"--\"))\n",
    "\n",
    "    x_patches = math.ceil((xmax - xmin)/ new_patch_size)\n",
    "    y_patches = math.ceil((ymax - ymin)/ new_patch_size)\n",
    "\n",
    "    for y_id in range(1, math.ceil(y_patches)+1):\n",
    "        for x_id in range(1, math.ceil(x_patches)+1):\n",
    "            tmp_x_corr, tmp_y_corr = xmin+((x_id-1)*new_patch_size), ymin+((y_id-1)*new_patch_size)\n",
    "            if (tmp_bn_img[tmp_y_corr:tmp_y_corr+new_patch_size, tmp_x_corr:tmp_x_corr+new_patch_size].sum()/ new_patch_size**2) >0.05:\n",
    "\n",
    "                path_he_thm  = he_slide.read_region((int(tmp_x_corr*scale_factor), int(tmp_y_corr*scale_factor)), 0, (patch_size, patch_size))\n",
    "\n",
    "                path_he_thm.save(os.path.join(path_to_save_patches, f'tile_{patch_size}_{int(tmp_x_corr*scale_factor)}_{int(tmp_y_corr*scale_factor)}.tif'))\n",
    "                # print(x_id-1,y_id-1)\n",
    "\n",
    "\n",
    "model = ComboGANModel(which_epoch=885, save_dir=os.path.join('./checkpoints', 'stain_aligned_comGan-512'),gpu_ids = gpu_ids)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2babdd2-2a3a-48a7-ad69-dbb5e9ff370f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                          | 1/21 [00:23<07:45, 23.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                          | 1/21 [00:40<13:32, 40.62s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mset_input(bundle)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     28\u001b[0m visuals \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_current_visuals(testing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Downloads/VS/models/combogan_model_pred.py:86\u001b[0m, in \u001b[0;36mComboGANModel.test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDA:\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m fake \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisuals\u001b[38;5;241m.\u001b[39mappend( fake )\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m.\u001b[39mappend( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfake_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m d )\n",
      "File \u001b[0;32m~/Downloads/VS/models/networks.py:382\u001b[0m, in \u001b[0;36mG_Plexer.decode\u001b[0;34m(self, input, domain)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msharing:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_decoder\u001b[38;5;241m.\u001b[39mforward(\u001b[38;5;28minput\u001b[39m, domain)\n\u001b[0;32m--> 382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/VS/models/networks.py:203\u001b[0m, in \u001b[0;36mResnetGenDecoder.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_ids \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdata, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mFloatTensor):\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39mdata_parallel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_ids)\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/vs/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/vs/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/vs/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.0/envs/vs/lib/python3.8/site-packages/torch/nn/modules/conv.py:956\u001b[0m, in \u001b[0;36mConvTranspose2d.forward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    951\u001b[0m num_spatial_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    952\u001b[0m output_padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_padding(\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28minput\u001b[39m, output_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    954\u001b[0m     num_spatial_dims, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m--> 956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_transpose2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_padding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_transform():\n",
    "    transform_list = []\n",
    "    transform_list.append(transforms.Resize(512, Image.BICUBIC))\n",
    "    transform_list += [transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                            (0.5, 0.5, 0.5))]\n",
    "    print(3)\n",
    "    return transforms.Compose(transform_list)\n",
    "\n",
    "\n",
    "# Get tiles paths\n",
    "path_tiles = natsorted(glob(os.path.join(path_to_save_patches, '*.tif')))\n",
    "\n",
    "transform = get_transform()\n",
    "for path in tqdm(path_tiles):\n",
    "    print(0)\n",
    "    he_img = Image.open(path).convert('RGB')\n",
    "\n",
    "    he_img = transform(he_img)\n",
    "    print(1)\n",
    "    bundle = {'A': torch.tensor(np.expand_dims(he_img, axis=0)), 'DA':\n",
    "              torch.tensor([8]), 'path': [path]}\n",
    "    print(2)\n",
    "    model.set_input(bundle)\n",
    "    print(3)\n",
    "    model.test()\n",
    "    print(4)\n",
    "    visuals = model.get_current_visuals(testing=True)\n",
    "    print(5)\n",
    "    short_path = os.path.basename(path)\n",
    "    name = os.path.splitext(short_path)[0]\n",
    "    for label, image_numpy in visuals.items():\n",
    "        image_name = '%s_%s.tif' % (name, label)\n",
    "        save_path = os.path.join('sample_staining', 'GAN', real_wsi_id,image_name)\n",
    "        Image.fromarray(image_numpy).save(save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e0b3dd1-1b15-470d-aba5-e348e11071ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  0.0431,  0.2392,  0.4275],\n",
       "         [ 1.0000,  1.0000,  1.0000,  ...,  0.1529,  0.3804,  0.4824],\n",
       "         [ 1.0000,  1.0000,  1.0000,  ...,  0.2863,  0.4667,  0.5216],\n",
       "         ...,\n",
       "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       "\n",
       "        [[ 1.0000,  1.0000,  1.0000,  ..., -0.4353, -0.3020, -0.1451],\n",
       "         [ 1.0000,  1.0000,  1.0000,  ..., -0.3647, -0.1686, -0.0824],\n",
       "         [ 1.0000,  1.0000,  1.0000,  ..., -0.2549, -0.1059, -0.0588],\n",
       "         ...,\n",
       "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       "\n",
       "        [[ 1.0000,  1.0000,  1.0000,  ...,  0.0431,  0.2157,  0.3412],\n",
       "         [ 1.0000,  1.0000,  1.0000,  ...,  0.1451,  0.3098,  0.3569],\n",
       "         [ 1.0000,  1.0000,  1.0000,  ...,  0.2471,  0.3412,  0.3412],\n",
       "         ...,\n",
       "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_img = Image.open(path).convert('RGB')\n",
    "transform(he_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7482c3-821f-43db-a44b-5bd9547ebc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for stain_id_fake in trange(0, 9):\n",
    "\n",
    "\n",
    "    # Get tiles paths\n",
    "    path_tiles = natsorted(glob(os.path.join('sample_staining', 'GAN', real_wsi_id, '*'+str(stain_id_fake)+'.tif')))\n",
    "\n",
    "    # Getting the x rows and y columns\n",
    "    _, patch_size, x_rows, y_colms, stain, modality =os.path.splitext(os.path.basename(path_tiles[len(path_tiles)-1]))[0].split('_')\n",
    "\n",
    "    x_mins, y_mins = [], []\n",
    "    for path in path_tiles:\n",
    "        # Getting the x rows and y columns\n",
    "        _, patch_size, x_min, y_min, stain, modality =os.path.splitext(os.path.basename(path))[0].split('_')\n",
    "\n",
    "        x_mins.append(int(x_min))\n",
    "        y_mins.append(int(y_min))\n",
    "\n",
    "\n",
    "    all_slide = np.ones((np.max(y_mins)-np.min(y_mins)+int(patch_size), np.max(x_mins)-np.min(x_mins)+int(patch_size), 3))*255\n",
    "\n",
    "    for path in path_tiles:\n",
    "        # Getting the x rows and y columns\n",
    "        _, patch_size, x_min, y_min, stain, modality =os.path.splitext(os.path.basename(path))[0].split('_')\n",
    "\n",
    "        x_min      = int(x_min) - np.min(x_mins)\n",
    "        y_min      = int(y_min) - np.min(y_mins)\n",
    "        patch_size = int(patch_size)\n",
    "\n",
    "        tmp_array = np.array(Image.open(path).resize((2048, 2048)))[:,:,0:3]\n",
    "\n",
    "\n",
    "        all_slide[y_min:y_min+patch_size, x_min:x_min+patch_size, :] = tmp_array\n",
    "\n",
    "    pyramid = pyvips.Image.new_from_array(all_slide)\n",
    "\n",
    "    del all_slide\n",
    "    # Add metadata\n",
    "    # metadata = {'ResolutionUnit': 'micrometers',\n",
    "    #             'openslide.mpp-x': float(lowlevel.get_property_value(low_slide,keys[108])),\n",
    "    #             'openslide.mpp-y': float(lowlevel.get_property_value(low_slide,keys[109])),\n",
    "    #             'openslide.objective-power': float(lowlevel.get_property_value(low_slide,keys[110])),\n",
    "    #             }shutil\n",
    "    # tiff.Model: C13210\n",
    "    # tiff.ResolutionUnit: centimeter\n",
    "    # tiff.Software: NDP.scan 3.2.15\n",
    "    # tiff.XResolution: 45344\n",
    "    # tiff.YResolution: 45344\n",
    "    # slide-associated-images: macro\n",
    "\n",
    "    # pyramid.set_type(pyvips.GValue.gint_type, \"openslide.objective-power\", metadata['openslide.objective-power'])\n",
    "    # pyramid.set_type(pyvips.GValue.gdouble_type,    \"openslide.mpp-x\", metadata['openslide.mpp-x'])\n",
    "    # pyramid.set_type(pyvips.GValue.gdouble_type,    \"openslide.mpp-y\", metadata['openslide.mpp-y'])\n",
    "    # pyramid.set_type(pyvips.GValue.gint_type,    \"tiff.XResolution\", 45344)\n",
    "    # pyramid.set_type(pyvips.GValue.gint_type,    \"tiff.YResolution\", 45344)\n",
    "    # pyramid.set_type(pyvips.GValue.gstr_type,    \"tiff.ResolutionUnit\", \"centimeter\")\n",
    "    # pyramid.set_type(pyvips.GValue.gstr_type,    \"tiff.Model\", \"C13210\")\n",
    "    # pyramid.set_type(pyvips.GValue.gstr_type,    \"tiff.Make\", \"Hamamatsu\")\n",
    "    # pyramid.set_type(pyvips.GValue.gint_type, \"hamamatsu.SourceLens\",40)\n",
    "\n",
    "    pyramid.tiffsave(os.path.join(save_WSIs, 'WSI_'+stain+'_'+modality+'.tif'), \n",
    "                compression=\"jpeg\", \n",
    "                Q=100, \n",
    "                tile=True, \n",
    "                tile_width=512, \n",
    "                tile_height=512, \n",
    "                pyramid=True)\n",
    "\n",
    "\n",
    "    del pyramid\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(path_to_save_patches)\n",
    "    shutil.rmtree(os.path.join('sample_staining', 'GAN', real_wsi_id))\n",
    "    print(\"Temp folders has been deleted.\")\n",
    "except OSError as e:\n",
    "    print(f\"Error: {e.strerror}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
