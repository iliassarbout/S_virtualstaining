{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43565b24-bbd8-4a70-b6a7-dc99db5fbd86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarbout/.pyenv/versions/3.7.5/envs/vs/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import binary_fill_holes, binary_dilation, binary_erosion\n",
    "from skimage.measure import label, regionprops\n",
    "import torchvision.transforms as transforms\n",
    "from models.combogan_model_pred import ComboGANModel\n",
    "import torch\n",
    "from imantics import Polygons, Mask, BBox\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from openslide import OpenSlide\n",
    "from collections import Counter\n",
    "from openslide import lowlevel\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "import pyvips\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ad0017-d0b8-426a-bc53-415172ba60a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [00:01<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks initialized -------------\n",
      "ResnetGenEncoder(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): PReLU(num_parameters=1)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): PReLU(num_parameters=1)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): PReLU(num_parameters=1)\n",
      "    (10): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (11): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (12): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (13): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ResnetGenDecoder(\n",
      "  (model): Sequential(\n",
      "    (0): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (1): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (2): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (3): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (4): ResnetBlock(\n",
      "      (conv_block): SequentialContext(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): PReLU(num_parameters=1)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (5): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (7): PReLU(num_parameters=1)\n",
      "    (8): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (10): PReLU(num_parameters=1)\n",
      "    (11): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (12): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n",
      "Created 9 Encoder-Decoder pairs\n",
      "Number of parameters per Encoder: 5099143\n",
      "Number of parameters per Deocder: 6565770\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarbout/.pyenv/versions/3.7.5/envs/vs/lib/python3.7/site-packages/torchvision/transforms/transforms.py:330: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:36<00:00,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp folders has been deleted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def extraction(he_slide_path,gpu_ids = [0],real_wsi_id = 'destination'):\n",
    "    # Choosing the magnification level\n",
    "    slide_dim_lvl = 5\n",
    "    # Patch size in pixels (x40) \n",
    "    patch_size = 2048\n",
    "    # Slide ID\n",
    "    #real_wsi_id = 'sample_vs'\n",
    "    # Path to save data\n",
    "    path_to_save_patches = os.path.join('sample_staining', 'he_patches', real_wsi_id)\n",
    "    os.makedirs(path_to_save_patches ,exist_ok=True)\n",
    "\n",
    "    # Path to save data\n",
    "    save_WSIs = os.path.join('sample_staining', 'slides', real_wsi_id)\n",
    "    os.makedirs(save_WSIs ,exist_ok=True)\n",
    "\n",
    "    os.makedirs(os.path.join('sample_staining', 'GAN', real_wsi_id) ,exist_ok=True) \n",
    "\n",
    "    # Opening the slides\n",
    "    he_slide  = OpenSlide(he_slide_path)\n",
    "    low_slide = lowlevel.open(he_slide_path)\n",
    "    keys = lowlevel.get_property_names(low_slide)\n",
    "\n",
    "    # Getting slides level dimensions\n",
    "    he_slide_levels = he_slide.level_dimensions\n",
    "\n",
    "\n",
    "    scale_factor = math.ceil(he_slide_levels[0][0]/he_slide_levels[slide_dim_lvl][0])\n",
    "    new_patch_size = math.ceil(patch_size/ scale_factor)\n",
    "\n",
    "    # Getting the thumbnail for the slides\n",
    "    he_thm  = he_slide.read_region((0, 0), slide_dim_lvl, he_slide_levels[slide_dim_lvl])\n",
    "\n",
    "    clean_label_image, polygons = cluster_wsi(he_thm, plot=False)\n",
    "\n",
    "\n",
    "    for poly_id in tqdm(range(len(polygons.points))):\n",
    "        tmp_bn_img = np.zeros(np.shape(clean_label_image))\n",
    "        rr, cc = np.where(clean_label_image==int(len(polygons.points)-poly_id))\n",
    "        tmp_bn_img[rr,cc] = 1\n",
    "\n",
    "        # plt.plot(polygons.points[poly_id][:,0], polygons.points[poly_id][:,1], label='Slide region: '+str(poly_id))\n",
    "        xmin, xmax = np.min(polygons.points[poly_id][:,0]), np.max(polygons.points[poly_id][:,0])\n",
    "        ymin, ymax = np.min(polygons.points[poly_id][:,1]), np.max(polygons.points[poly_id][:,1])\n",
    "        # plt.gca().add_patch(Rectangle((xmin, ymin), xmax-xmin, ymax-ymin,edgecolor='gray', facecolor='none', lw=1, ls=\"--\"))\n",
    "\n",
    "        x_patches = math.ceil((xmax - xmin)/ new_patch_size)\n",
    "        y_patches = math.ceil((ymax - ymin)/ new_patch_size)\n",
    "\n",
    "        for y_id in range(1, math.ceil(y_patches)+1):\n",
    "            for x_id in range(1, math.ceil(x_patches)+1):\n",
    "                tmp_x_corr, tmp_y_corr = xmin+((x_id-1)*new_patch_size), ymin+((y_id-1)*new_patch_size)\n",
    "                if (tmp_bn_img[tmp_y_corr:tmp_y_corr+new_patch_size, tmp_x_corr:tmp_x_corr+new_patch_size].sum()/ new_patch_size**2) >0.05:\n",
    "\n",
    "                    path_he_thm  = he_slide.read_region((int(tmp_x_corr*scale_factor), int(tmp_y_corr*scale_factor)), 0, (patch_size, patch_size))\n",
    "\n",
    "                    path_he_thm.save(os.path.join(path_to_save_patches, f'tile_{patch_size}_{int(tmp_x_corr*scale_factor)}_{int(tmp_y_corr*scale_factor)}.tif'))\n",
    "                    # print(x_id-1,y_id-1)\n",
    "\n",
    "\n",
    "    model = ComboGANModel(which_epoch=885, save_dir=os.path.join('./checkpoints', 'stain_aligned_comGan-512'),gpu_ids = gpu_ids)\n",
    "\n",
    "    def get_transform():\n",
    "        transform_list = []\n",
    "        transform_list.append(transforms.Resize(512, Image.BICUBIC))\n",
    "        transform_list += [transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                (0.5, 0.5, 0.5))]\n",
    "        return transforms.Compose(transform_list)\n",
    "\n",
    "\n",
    "    # Get tiles paths\n",
    "    path_tiles = natsorted(glob(os.path.join(path_to_save_patches, '*.tif')))\n",
    "\n",
    "    transform = get_transform()\n",
    "    for path in path_tiles:\n",
    "        he_img = Image.open(path).convert('RGB')\n",
    "\n",
    "        he_img = transform(he_img)\n",
    "\n",
    "        bundle = {'A': torch.tensor(np.expand_dims(he_img, axis=0)), 'DA':\n",
    "                  torch.tensor([8]), 'path': [path]}\n",
    "        model.set_input(bundle)\n",
    "        model.test()\n",
    "        visuals = model.get_current_visuals(testing=True)\n",
    "\n",
    "        short_path = os.path.basename(path)\n",
    "        name = os.path.splitext(short_path)[0]\n",
    "\n",
    "        for label, image_numpy in visuals.items():\n",
    "            image_name = '%s_%s.tif' % (name, label)\n",
    "            save_path = os.path.join('sample_staining', 'GAN', real_wsi_id,image_name)\n",
    "            Image.fromarray(image_numpy).save(save_path)\n",
    "\n",
    "\n",
    "\n",
    "    for stain_id_fake in trange(0, 9):\n",
    "\n",
    "\n",
    "        # Get tiles paths\n",
    "        path_tiles = natsorted(glob(os.path.join('sample_staining', 'GAN', real_wsi_id, '*'+str(stain_id_fake)+'.tif')))\n",
    "\n",
    "        # Getting the x rows and y columns\n",
    "        _, patch_size, x_rows, y_colms, stain, modality =os.path.splitext(os.path.basename(path_tiles[len(path_tiles)-1]))[0].split('_')\n",
    "\n",
    "        x_mins, y_mins = [], []\n",
    "        for path in path_tiles:\n",
    "            # Getting the x rows and y columns\n",
    "            _, patch_size, x_min, y_min, stain, modality =os.path.splitext(os.path.basename(path))[0].split('_')\n",
    "\n",
    "            x_mins.append(int(x_min))\n",
    "            y_mins.append(int(y_min))\n",
    "\n",
    "\n",
    "        all_slide = np.ones((np.max(y_mins)-np.min(y_mins)+int(patch_size), np.max(x_mins)-np.min(x_mins)+int(patch_size), 3))*255\n",
    "\n",
    "        for path in path_tiles:\n",
    "            # Getting the x rows and y columns\n",
    "            _, patch_size, x_min, y_min, stain, modality =os.path.splitext(os.path.basename(path))[0].split('_')\n",
    "\n",
    "            x_min      = int(x_min) - np.min(x_mins)\n",
    "            y_min      = int(y_min) - np.min(y_mins)\n",
    "            patch_size = int(patch_size)\n",
    "\n",
    "            tmp_array = np.array(Image.open(path).resize((2048, 2048)))[:,:,0:3]\n",
    "\n",
    "\n",
    "            all_slide[y_min:y_min+patch_size, x_min:x_min+patch_size, :] = tmp_array\n",
    "\n",
    "        pyramid = pyvips.Image.new_from_array(all_slide)\n",
    "\n",
    "        del all_slide\n",
    "        # Add metadata\n",
    "        # metadata = {'ResolutionUnit': 'micrometers',\n",
    "        #             'openslide.mpp-x': float(lowlevel.get_property_value(low_slide,keys[108])),\n",
    "        #             'openslide.mpp-y': float(lowlevel.get_property_value(low_slide,keys[109])),\n",
    "        #             'openslide.objective-power': float(lowlevel.get_property_value(low_slide,keys[110])),\n",
    "        #             }shutil\n",
    "        # tiff.Model: C13210\n",
    "        # tiff.ResolutionUnit: centimeter\n",
    "        # tiff.Software: NDP.scan 3.2.15\n",
    "        # tiff.XResolution: 45344\n",
    "        # tiff.YResolution: 45344\n",
    "        # slide-associated-images: macro\n",
    "\n",
    "        # pyramid.set_type(pyvips.GValue.gint_type, \"openslide.objective-power\", metadata['openslide.objective-power'])\n",
    "        # pyramid.set_type(pyvips.GValue.gdouble_type,    \"openslide.mpp-x\", metadata['openslide.mpp-x'])\n",
    "        # pyramid.set_type(pyvips.GValue.gdouble_type,    \"openslide.mpp-y\", metadata['openslide.mpp-y'])\n",
    "        # pyramid.set_type(pyvips.GValue.gint_type,    \"tiff.XResolution\", 45344)\n",
    "        # pyramid.set_type(pyvips.GValue.gint_type,    \"tiff.YResolution\", 45344)\n",
    "        # pyramid.set_type(pyvips.GValue.gstr_type,    \"tiff.ResolutionUnit\", \"centimeter\")\n",
    "        # pyramid.set_type(pyvips.GValue.gstr_type,    \"tiff.Model\", \"C13210\")\n",
    "        # pyramid.set_type(pyvips.GValue.gstr_type,    \"tiff.Make\", \"Hamamatsu\")\n",
    "        # pyramid.set_type(pyvips.GValue.gint_type, \"hamamatsu.SourceLens\",40)\n",
    "\n",
    "        pyramid.tiffsave(os.path.join(save_WSIs, 'WSI_'+stain+'_'+modality+'.tif'), \n",
    "                    compression=\"jpeg\", \n",
    "                    Q=100, \n",
    "                    tile=True, \n",
    "                    tile_width=512, \n",
    "                    tile_height=512, \n",
    "                    pyramid=True)\n",
    "\n",
    "\n",
    "        del pyramid\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(path_to_save_patches)\n",
    "        shutil.rmtree(os.path.join('sample_staining', 'GAN', real_wsi_id))\n",
    "        print(\"Temp folders has been deleted.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: {e.strerror}\")\n",
    "\n",
    "        \n",
    "he_slide_path  = 'HE.ndpi'\n",
    "extraction(he_slide_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
